{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Keras ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core data structure of Keras is a model, a way to organize layers. \n",
    "The simplest type of model is the Sequential model, a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we'll use Keras sequential model to recognize handwritten digit from MNIST database ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 26s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # Dataset of 60,000 28x28 grayscale images of the 10 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape # test set of 10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123bfef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(x_train[5]) #check random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the basic information of the model\n",
    "# m_train = 60000\n",
    "# m_train = 10000\n",
    "# We'll flatten input X to flatten it\n",
    "# Each input - 28 x 28 = 784 input features; nx = 784\n",
    "# We'll scale X by dividing by 256\n",
    "\n",
    "# y - currently has int data 0-9\n",
    "# these needs to be converted to categorical values\n",
    "\n",
    "# We'll have sequential model\n",
    "# Now we'll have a Dense layer - with 256 units in that layer\n",
    "# Then a Dropout layer - to prevent overfitting \n",
    "# Then another Dense layer - with 128 units in this layer\n",
    "# Then a Dropout layer \n",
    "# Then a Dense layer - 10 units - for softmax classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000,784))\n",
    "x_test = x_test.reshape((10000,784))\n",
    "x_train = x_train/256\n",
    "x_test = x_test/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01171875, 0.0703125 , 0.0703125 ,\n",
       "       0.0703125 , 0.4921875 , 0.53125   , 0.68359375, 0.1015625 ,\n",
       "       0.6484375 , 0.99609375, 0.96484375, 0.49609375, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1171875 , 0.140625  , 0.3671875 , 0.6015625 ,\n",
       "       0.6640625 , 0.98828125, 0.98828125, 0.98828125, 0.98828125,\n",
       "       0.98828125, 0.87890625, 0.671875  , 0.98828125, 0.9453125 ,\n",
       "       0.76171875, 0.25      , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19140625, 0.9296875 ,\n",
       "       0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125,\n",
       "       0.98828125, 0.98828125, 0.98828125, 0.98046875, 0.36328125,\n",
       "       0.3203125 , 0.3203125 , 0.21875   , 0.15234375, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0703125 , 0.85546875, 0.98828125, 0.98828125,\n",
       "       0.98828125, 0.98828125, 0.98828125, 0.7734375 , 0.7109375 ,\n",
       "       0.96484375, 0.94140625, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3125    , 0.609375  , 0.41796875, 0.98828125, 0.98828125,\n",
       "       0.80078125, 0.04296875, 0.        , 0.16796875, 0.6015625 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.0546875 ,\n",
       "       0.00390625, 0.6015625 , 0.98828125, 0.3515625 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54296875,\n",
       "       0.98828125, 0.7421875 , 0.0078125 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04296875, 0.7421875 , 0.98828125,\n",
       "       0.2734375 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13671875, 0.94140625, 0.87890625, 0.625     ,\n",
       "       0.421875  , 0.00390625, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31640625, 0.9375    , 0.98828125, 0.98828125, 0.46484375,\n",
       "       0.09765625, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17578125,\n",
       "       0.7265625 , 0.98828125, 0.98828125, 0.5859375 , 0.10546875,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0625    , 0.36328125,\n",
       "       0.984375  , 0.98828125, 0.73046875, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97265625, 0.98828125,\n",
       "       0.97265625, 0.25      , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1796875 , 0.5078125 ,\n",
       "       0.71484375, 0.98828125, 0.98828125, 0.80859375, 0.0078125 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15234375,\n",
       "       0.578125  , 0.89453125, 0.98828125, 0.98828125, 0.98828125,\n",
       "       0.9765625 , 0.7109375 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09375   , 0.4453125 , 0.86328125, 0.98828125, 0.98828125,\n",
       "       0.98828125, 0.98828125, 0.78515625, 0.3046875 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08984375, 0.2578125 , 0.83203125, 0.98828125,\n",
       "       0.98828125, 0.98828125, 0.98828125, 0.7734375 , 0.31640625,\n",
       "       0.0078125 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0703125 , 0.66796875, 0.85546875,\n",
       "       0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.76171875,\n",
       "       0.3125    , 0.03515625, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21484375, 0.671875  ,\n",
       "       0.8828125 , 0.98828125, 0.98828125, 0.98828125, 0.98828125,\n",
       "       0.953125  , 0.51953125, 0.04296875, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53125   , 0.98828125, 0.98828125, 0.98828125,\n",
       "       0.828125  , 0.52734375, 0.515625  , 0.0625    , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\einchat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "model.add( Dense(256, input_shape=(784,), activation='relu') )\n",
    "model.add( Dropout(rate=0.2) )\n",
    "model.add( Dense(128, activation='relu') )\n",
    "model.add( Dropout(rate=0.2) )\n",
    "model.add( Dense(num_class,activation='softmax') )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for above\n",
    "# https://keras.io/optimizers/\n",
    "# https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\einchat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3677 - acc: 0.8911 - val_loss: 0.1710 - val_acc: 0.9457\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1580 - acc: 0.9531 - val_loss: 0.1078 - val_acc: 0.9655\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1120 - acc: 0.9655 - val_loss: 0.0881 - val_acc: 0.9732\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0891 - acc: 0.9728 - val_loss: 0.0800 - val_acc: 0.9758\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0747 - acc: 0.9772 - val_loss: 0.0715 - val_acc: 0.9783\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0661 - acc: 0.9796 - val_loss: 0.0778 - val_acc: 0.9750\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0565 - acc: 0.9828 - val_loss: 0.0670 - val_acc: 0.9815\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0498 - acc: 0.9842 - val_loss: 0.0660 - val_acc: 0.9815\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0427 - acc: 0.9860 - val_loss: 0.0738 - val_acc: 0.9800\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0413 - acc: 0.9866 - val_loss: 0.0659 - val_acc: 0.9824\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0360 - acc: 0.9887 - val_loss: 0.0690 - val_acc: 0.9824\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0336 - acc: 0.9896 - val_loss: 0.0664 - val_acc: 0.9828\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0322 - acc: 0.9896 - val_loss: 0.0827 - val_acc: 0.9808\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0766 - val_acc: 0.9807\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0265 - acc: 0.9913 - val_loss: 0.0712 - val_acc: 0.9819\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0266 - acc: 0.9914 - val_loss: 0.0713 - val_acc: 0.9824\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.0707 - val_acc: 0.9840\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0254 - acc: 0.9919 - val_loss: 0.0700 - val_acc: 0.9822\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.0741 - val_acc: 0.9829oss: 0.0228 - acc:\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 0.0814 - val_acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=20, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08138560987974275\n",
      "Test accuracy: 0.9824\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is created with help of documentation at keras.io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
