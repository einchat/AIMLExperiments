{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network (with one hidden layer) from scratch ##\n",
    "#### Purpose of the neural network : 2 class classification ####\n",
    "### Learning objective: various activation functions, compute cross entropy loss, forward & backward propagation, random initialization ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here input data X : has two input features (both are real numbers)\n",
    "# Y : has two classes 0, 1\n",
    "# We'll generate X, Y with help of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create data set\n",
    "# create a flower like structure\n",
    "\n",
    "def load_planar_dataset(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    m = 400 # number of examples\n",
    "    N = int(m/2) # number of points per class; N=200\n",
    "    D = 2 # dimensionality; two classes\n",
    "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
    "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
    "    a = 4 # maximum ray of the flower\n",
    "\n",
    "    for j in range(2):\n",
    "        ix = range(N*j,N*(j+1))# 0-199; 200-399;\n",
    "        \n",
    "        # numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)\n",
    "        # Return evenly spaced numbers over a specified interval\n",
    "        \n",
    "        # numpy.random.randn(d0, d1, ..., dn)\n",
    "        # d0, d1, …, dn : int, optional - The dimensions of the returned array\n",
    "        # Return a sample (or samples) from the “standard normal” distribution\n",
    "        \n",
    "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
    "        \n",
    "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
    "        \n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)] \n",
    "        # numpy.c_ Translates slice objects to concatenation along the second axis\n",
    "        \n",
    "        Y[ix] = j\n",
    "        \n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 400)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # X - the x(i)s are stacked horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape # Y - the y(i)s are stacked horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xd21be80>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Visualize the data:\n",
    "plt.scatter(X[0, :], X[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0063551  0.41813177] [0] [-1.68448953 -3.76359366] [1]\n"
     ]
    }
   ],
   "source": [
    "# checking some random data\n",
    "print(X[:,15], Y[:,15], X[:,228], Y[:,228] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Logistic Regression from Scikit learn - just to compare with NN model to be developed later ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\einchat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\einchat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = sklearn.linear_model.LogisticRegressionCV(); # logisic regression with built is cross validation\n",
    "classifier.fit(X.T, Y.T); \n",
    "# in fit function X should have the dimension (m,nx); Y - (m,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy\n",
    "LR_predictions = classifier.predict(X.T)\n",
    "print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"(percentage of correctly labelled datapoints)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using an available function ## facing problem with this function\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will have the following model\n",
    "\n",
    "# Input layer - [0] : X = A0 - two input features - so n0=2; A0 - [n0 x m]\n",
    "# One hidden layer - [1] - n1 hidden units - n1=4 ; Activation function: tanh\n",
    "# Output layer [2] - n2 unit - n2=1; Activation function: sigmoid\n",
    "\n",
    "# Parameters for [1]\n",
    "# W1 - [n1 x n0] = [4 x 2] matrix\n",
    "# b1 - [n1 x 1] = [4 x 1] matrix\n",
    "\n",
    "# Parameters for [2]\n",
    "# W2 - [n2 x n1] = [1 x 4] matrix\n",
    "# b2 - [n2 x 1] = [1 x 1] matrix\n",
    "\n",
    "# Forward Pass\n",
    "# Z1 = W1 x A0 + b1 => [n1 x n0] x [n0 x m] + [n1 x 1] ==> [n1 x m]\n",
    "# A1 = tanh(Z1) => [n1 x m]\n",
    "# Z2 = W2 x A1 + b2 => [n2 x n1] x [n1 x m] + [n2 x 1] ==> [n2 x m]\n",
    "# Yhat= A2 = sigmoid(Z2) => [n2 x m] = [1 x m] -- this is same as dimension of Y\n",
    "\n",
    "# Cost function\n",
    "# This is binary classification - so cost function is as follows:\n",
    "# J = (-1/m)Sum (Y*log(Yhat)+(1-Y)*log(1-Yhat))\n",
    "\n",
    "# Backward Pass\n",
    "# dZ2 = A2 - Y; dimension [n2 x m]\n",
    "# dW2 = (1/m) dZ2 x A1.T ; dim check - [n2 x m] x [m x n1] => [n2 x n1] -- same as W2\n",
    "# db2 = (1/m) Sum(dZ2, column-wise sum) => [n2 x 1] -- same as b2\n",
    "# dZ1 = W2.T x dZ2 * g1prime(Z1) => [n1 x n2] x [n2 x m] * [n1 x m] => [n1 x m]; g1prime - derivative of g1 i,e, tanh\n",
    "# dW1 = (1/m) dZ1 x A0.T; [n1 x m] x [m x n0] => [n1 x n0] -- same as W1\n",
    "# db1 = (1/m) Sum(dZ1, column-wise sum) => [n1 x 1] -- same as b1\n",
    "\n",
    "# Update\n",
    "# W1 = W1 - alpha.dW1 and so on\n",
    "\n",
    "# What are variables\n",
    "# n0, n1, n2; \n",
    "\n",
    "# Functions to write in order to modularize\n",
    "# Initialize parameters - arg: n0, n1, n2; function: random initialization of W,b s and return them\n",
    "# Forward Pass function - arg: A0=X, W, b; function: calculate A2 and J\n",
    "# Backward Pass function - arg: A2, Y; function: calculate derivatives and update W,b\n",
    "# Predict function - arg: X_test; function: calculate Yhat_test and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(numberOfLayers, listNumberOfUnits):\n",
    "    \"\"\"\n",
    "    numberOfLayers - int - should include input layer also\n",
    "    listNumberOfUnits - array of int - units in each layer\n",
    "    \n",
    "    Returns:\n",
    "    a dictionary - parameters for W's and b's\n",
    "    \"\"\"\n",
    "    parameter = {} # start with empty dictionary\n",
    "    \n",
    "    for layer in range(1,numberOfLayers):\n",
    "        print(listNumberOfUnits[layer],listNumberOfUnits[layer-1])\n",
    "        Wlayer = np.random.randn(listNumberOfUnits[layer], listNumberOfUnits[layer-1]) * 0.01\n",
    "        blayer = np.zeros((listNumberOfUnits[layer],1))\n",
    "        parameter[\"W\"+str(layer)] = Wlayer\n",
    "        parameter[\"b\"+str(layer)] = blayer\n",
    "    \n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n",
      "1 4\n"
     ]
    }
   ],
   "source": [
    "# test the initialize_parameters function\n",
    "numberOfLayers = 3 # including input layer\n",
    "listNumberOfUnits = [2,4,1]\n",
    "parameter=initialize_parameters(numberOfLayers, listNumberOfUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter[\"W1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter[\"W2\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00209097,  0.01555016, -0.00569149, -0.01061797]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter[\"W2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X,Y, parameter):\n",
    "    \"\"\"\n",
    "    X - input - dimension [n0 x m]; Note: X=A0; n0=nx;\n",
    "    Y - ground truth - [nL x m]\n",
    "    parameter - dictionary - contains W's, b's\n",
    "    \n",
    "    Returns:\n",
    "    activation values - dictionary\n",
    "    J - cost \n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    numberLayers = int(len(parameter)/2) # this is without input layer - if len(parameter)==10 - then means 5 layers\n",
    "    A_prev = X\n",
    "    J = 0\n",
    "    activation = {} # start with empty dictionary\n",
    "    activation['0'] = X\n",
    "    \n",
    "    for layer in range(1,numberLayers+1): # i.e. 1 to 5\n",
    "        W = parameter[\"W\" + str(layer)]\n",
    "        b = parameter[\"b\" + str(layer)]\n",
    "        #print('layer' + str(layer))\n",
    "        #print('shape: W')\n",
    "        #print(W.shape)\n",
    "        #print('shape: A_prev')\n",
    "        #print(A_prev.shape)\n",
    "        Z = np.dot(W,A_prev) + b\n",
    "        if layer != numberLayers:\n",
    "            A = activationFunction(Z, 'tanh')\n",
    "        else:\n",
    "            A = activationFunction(Z, 'sigmoid')\n",
    "        activation[str(layer)]= A\n",
    "        A_prev = A\n",
    "    \n",
    "    # at end of iteration, Yhat = A\n",
    "    \n",
    "    J = (-1/m)*np.sum( Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    \n",
    "    return activation,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the activation function \n",
    "# Assumption: hidden layer - tanh activation function; output layer - sigmoid function\n",
    "def activationFunction(Z, fn='tanh'):\n",
    "    \"\"\"\n",
    "    Z - a matrix\n",
    "    layer - int - indicating the current layer\n",
    "    \n",
    "    Returns:\n",
    "    result of activation \n",
    "    \"\"\"\n",
    "    if fn== 'sigmoid':\n",
    "        # sigmoid\n",
    "        A = 1/(1+np.exp(-Z))\n",
    "    else:\n",
    "        # tanh\n",
    "        A = (np.exp(Z)-np.exp(-Z))/(np.exp(Z)+np.exp(-Z))\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test activationFunction\n",
    "activationFunction(0,\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activationFunction(0,\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9999999958776926"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activationFunction(-10,\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Pass\n",
    "# dZ2 = A2 - Y; dimension [n2 x m]\n",
    "# dW2 = (1/m) dZ2 x A1.T ; dim check - [n2 x m] x [m x n1] => [n2 x n1] -- same as W2\n",
    "# db2 = (1/m) Sum(dZ2, column-wise sum) => [n2 x 1] -- same as b2\n",
    "# dZ1 = W2.T x dZ2 * g1prime(Z1) => [n1 x n2] x [n2 x m] * [n1 x m] => [n1 x m]; g1prime - derivative of g1 i,e, tanh\n",
    "### derivative of tanh(Z) = 1- tanh(Z)^2\n",
    "# dW1 = (1/m) dZ1 x A0.T; [n1 x m] x [m x n0] => [n1 x n0] -- same as W1\n",
    "# db1 = (1/m) Sum(dZ1, column-wise sum) => [n1 x 1] -- same as b1\n",
    "\n",
    "# Backward Pass function - arg: A2, Y; function: calculate derivatives and update W,b\n",
    "\n",
    "def backward_pass(Yhat, Y, parameter, activation, alpha=0.01):\n",
    "    \"\"\"\"\n",
    "    Yhat, Y - [nL x m]\n",
    "    parameter - dictionary containing W's, b's\n",
    "    activation - dictionary conatining activation values\n",
    "    \n",
    "    Returns:\n",
    "    updated parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    numberLayers = int(len(parameter)/2) # this is without the input layer\n",
    "    \n",
    "    ## shall try the loop based implementation layer\n",
    "    ## now lets do basic calculation\n",
    "    dZ2 = Yhat - Y\n",
    "    dW2 = (1/m)*np.dot(dZ2, activation['1'].T)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.dot(parameter[\"W2\"].T,dZ2) * (1 - np.power(activation['1'], 2))# g1prime -- tanh-derivative - 1-a^2;\n",
    "    dW1 = (1/m)* np.dot(dZ1, activation['0'].T)\n",
    "    db1 = (1/m)* np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    parameter['W1'] = parameter['W1'] - alpha* dW1\n",
    "    parameter['b1'] = parameter['b1'] - alpha* db1\n",
    "    parameter['W2'] = parameter['W2'] - alpha* dW2\n",
    "    parameter['b2'] = parameter['b2'] - alpha* db2\n",
    "    \n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 400)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n",
      "1 4\n",
      "Iteration 0\n",
      "Cost0.6931621661402946\n",
      "Iteration 1000\n",
      "Cost0.25862506828690474\n",
      "Iteration 2000\n",
      "Cost0.2393335165458315\n",
      "Iteration 3000\n",
      "Cost0.23080163442975746\n",
      "Iteration 4000\n",
      "Cost0.2255280270817635\n",
      "Iteration 5000\n",
      "Cost0.221844675950227\n",
      "Iteration 6000\n",
      "Cost0.21909438354878738\n",
      "Iteration 7000\n",
      "Cost0.2206059477385167\n",
      "Iteration 8000\n",
      "Cost0.21939415031175855\n",
      "Iteration 9000\n",
      "Cost0.21848062185993705\n",
      "Iteration 10000\n",
      "Cost0.21773715034491392\n",
      "Iteration 11000\n",
      "Cost0.2171129219042612\n",
      "Iteration 12000\n",
      "Cost0.21657724801406075\n",
      "Iteration 13000\n",
      "Cost0.2161096988101459\n",
      "Iteration 14000\n",
      "Cost0.21569602938821353\n",
      "Iteration 15000\n",
      "Cost0.2153259648926916\n",
      "Iteration 16000\n",
      "Cost0.21499187546572515\n",
      "Iteration 17000\n",
      "Cost0.21468794744001402\n",
      "Iteration 18000\n",
      "Cost0.2144096488651103\n",
      "Iteration 19000\n",
      "Cost0.2141533757143732\n"
     ]
    }
   ],
   "source": [
    "## actual running the model\n",
    "np.random.seed(3)\n",
    "numberOfIteration = 20000\n",
    "numberOfLayers = 3\n",
    "listNumberOfUnits = [2,4,1]\n",
    "alpha = 1.2\n",
    "parameter = initialize_parameters(numberOfLayers, listNumberOfUnits)\n",
    "for i in range(numberOfIteration):\n",
    "    #print('i '+str(i))\n",
    "    activation,J = forward_pass(X,Y, parameter)\n",
    "    if (i%1000==0):\n",
    "        print('Iteration '+str(i))\n",
    "        print('Cost' + str(J))\n",
    "    \n",
    "    Yhat = activation[str(numberOfLayers-1)]\n",
    "    parameter = backward_pass(Yhat, Y, parameter, activation, alpha)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.23170772  -4.10699665]\n",
      " [  0.15721204 -10.61130347]\n",
      " [ 15.21150097  17.56780148]\n",
      " [ 11.24307005 -12.21754247]]\n"
     ]
    }
   ],
   "source": [
    "print (parameter['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48568691]\n",
      " [0.02886921]\n",
      " [0.05850066]\n",
      " [0.01906178]]\n"
     ]
    }
   ],
   "source": [
    "print(parameter['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.5832056  -13.03589833  -6.66198143  11.19409684]]\n"
     ]
    }
   ],
   "source": [
    "print(parameter['W2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07092283]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter['b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function - arg: X_test; function: calculate Yhat_test and return\n",
    "def predict_class(X_test, parameters):\n",
    "    \"\"\"\n",
    "    X - input - dimension [n0 x m]; Note: X=A0; n0=nx;\n",
    "    parameter - dictionary - contains W's, b's\n",
    "    \n",
    "    Returns:\n",
    "    Yhat - [nL x m] matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X_test.shape[1]\n",
    "    numberLayers = int(len(parameter)/2) # this is without input layer - if len(parameter)==10 - then means 5 layers\n",
    "    A_prev = X_test\n",
    "    \n",
    "    for layer in range(1,numberLayers+1): # i.e. 1 to 5\n",
    "        W = parameter[\"W\" + str(layer)]\n",
    "        b = parameter[\"b\" + str(layer)]\n",
    "        Z = np.dot(W,A_prev) + b\n",
    "        if layer != numberLayers:\n",
    "            A = activationFunction(Z, 'tanh')\n",
    "        else:\n",
    "            A = activationFunction(Z, 'sigmoid')\n",
    "        A_prev = A\n",
    "    \n",
    "    # at end of iteration, Yhat = A\n",
    "    # Now if probability > 0.5 - we'll classify as 1; otherwise 0\n",
    "    Yhat = A>0.5\n",
    "    \n",
    "    return Yhat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = predict_class(X, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90%\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: %d' % float((np.dot(Y,Predictions.T) + np.dot(1-Y,1-Predictions.T))/float(Y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So this is better than the logistic regression result ####\n",
    "#### however there is a flaw that we are training and testing on the same generated dataset ####\n",
    "#### So let us load the dataset by changing the random seed and see ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = predict_class(X, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91%\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: %d' % float((np.dot(Y,Predictions.T) + np.dot(1-Y,1-Predictions.T))/float(Y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of notebook ###\n",
    "### Learnings ###\n",
    "#### Generate data set ####\n",
    "#### Write initialization, forward, backward, predict functions ####\n",
    "#### Idea on a simple NN with one hidden layer written from scratch ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above coding is inspired by the deep learning course of Prof. Andrew Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
